---
title: "VA with CppAD for GSM"
author: Benjamin Christoffersen
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  error = FALSE, cache = "./README-cache/", fig.path = "figures/README-", 
  echo = TRUE)
options(digits = 4, scipen = 7)
.fig_height_small <- 4
palette(c("#000000", "#009E73", "#e79f00", "#9ad0f3", "#0072B2", "#D55E00", 
          "#CC79A7", "#F0E442"))
```

This package is made to 

 - show implementations of Laplace approximations and Gaussian quadrature 
   using `CppAD` through `TMB`. 
 - show implementations of variational approximation in generalized survival 
   models (GSM).
 - how to use `TMB` to get extra operators for `CppAD` and make `CppAD` work 
   with `Eigen`. 
 - use `TMB` and `Rcpp` together and have multiple C++ functions which can  
   be used for R without one function with a switch statement.
   
The latter may be advantageous later as we can work more solely in C++. You 
can contrast the solution here with the discussion made in 
[this post](https://github.com/kaskr/adcomp/issues/247#issuecomment-475002639).
We start by using a temporary directory as our working directory throughout
the rest of the code

```{r set_dir}
old_dir <- getwd()
dir_use <- tempdir()
knitr::opts_knit$set(root.dir = dir_use)
```

We also load a few libraries

```{r load_lib}
library(GSMVAEx)
library(TMB)
```

## log-log GSM
So far, we just compute the gradient of log-log GSM in `C++` and compare it 
with using `TMB` from R. Here is the `loglogTMBEx.cpp` file which we will use
in `R`

```{r show_loglog_code, engine="C++", code = readLines("README/loglogTMBEx.cpp"), eval = FALSE}
```

We make a copy of the file in the temporary directory and compile the code.

```{r cmp_loglog_code, cache = 1}
stopifnot(
  file.copy(file.path(old_dir, "README", "loglogTMBEx.cpp"),
          "loglogTMBEx.cpp"),
  compile("loglogTMBEx.cpp") == 0)
dyn.load(dynlib("loglogTMBEx"))
```

Then we have a bit of R code which we need in order to simulate the data
and which we use in subsequent code (this is some code I received and there 
seems to be a bug in it)

```{r tmb_loglog_from_R, cache = 1, dependson = "cmp_loglog_code"}
require(splines)
set.seed(12345)
x <- seq(0, 1, length=1e4)
time <- rweibull(length(x), 1, exp(.1+0.1*x))
censor <- runif(length(x), 0, 5)
event <- time < censor
tobs <- pmin(censor, time)
formula <- ~ x + ns(log(tobs) , df = 1)

# get the terms object we want
trms_use <- local({
  mf <- model.frame(formula, data.frame(tobs = tobs, x = x)[event, ])
  terms(mf)
})

getXD <- function(trms, newdata, time, eps = 1e-5) {
  stopifnot(inherits(trms, "terms"))
  newdata[[time]] <- newdata[[time]] + eps
  upper <- model.matrix(trms, newdata)
  newdata[[time]] <- newdata[[time]] - eps
  (upper - model.matrix(trms, newdata)) / 2 / eps
}

dat <- data.frame(tobs, x)
X <- model.matrix(trms_use, data.frame(tobs, x))
XD <- getXD(trms_use, dat, time = "tobs")

MakeADFun <- function(...) {
  newobj <- TMB::MakeADFun(...)
  newobj$call <- match.call()
  newobj
}
```

We compare the computation of the gradient in C++ in this package 
with the one using the `TMB` interface from `R`

```{r comp_grads_loglog, cache = 1, dependson = "tmb_loglog_from_R"}
local({
  # assign functions to do the recording and compute the gradient
  tmb <- function(){
    f <- MakeADFun(
      data = list(X = X, XD = XD, tobs = tobs, event = as.double(event),
                  eps = 1e-6, kappa = 1.0),
      parameters = list(beta = c(-5, 0, 1)), method = "nlminb",
      DLL = "loglogTMBEx", silent = TRUE)
    
    structure(f$gr(c(-5, 0, 1)), func = f)
  }
  imp <- function()
    GSMVAEx::loglog(tobs = tobs, event = as.double(event), XD = XD, X = X, 
                    eps = 1e-6, kappa = 1.0, beta = c(-5, 0, 1))
  
  # we get the same gradient
  stopifnot(isTRUE(all.equal(c(tmb()), c(imp()))))
  
  cat("The computation time are comparable\n")
  print(microbenchmark::microbenchmark(TBM = tmb(), Implementation = imp(), 
                                       times = 100))
  
  cat("\nA large part is the \"tape recording\"\n")
  f <- attr(tmb(), "func")
  microbenchmark::microbenchmark(
    `Full cost`          = tmb(),
    `Non recording cost` = f$gr(c(-5, 0, 1)), times = 100)
})
```

Of course, one of the nice things about `MakeADFun` is that we do not have 
to do the recording over and over again and save a lot of computation time. 
We can similarly save a pointer to a C++ object in our implementation. 

### Optimization in C++

We can also compare computation of the parameters. This is done in the C++
code using the `nlopt` library through the `nloptr` package

```{r show_parameter_estimation, cache = 1, dependson = "tmb_loglog_from_R"}
local({
  # assign functions to do the recording and compute the gradient
  tmb <- function(){
    f <- MakeADFun(
      data = list(X = X, XD = XD, tobs = tobs, event = as.double(event),
                  eps = 1e-6, kappa = 1.0),
        parameters = list(beta = c(-5, 0, 1)), method = "nlminb",
      DLL = "loglogTMBEx", silent = TRUE)
    opt <- optim(c(-5, 0, 1), fn = f$fn, gr = f$gr)
    opt[c("par", "value")]
  }
  imp <- function()
    GSMVAEx::loglog_opt(
      tobs = tobs, event = as.double(event), XD = XD, X = X, eps = 1e-6, 
      kappa = 1.0, beta = c(-5, 0, 1))
  
  # we get the same result
  stopifnot(isTRUE(all.equal(tmb(), imp(), tolerance = 1e-4)))
  
  cat("The computation time are comparable\n")
  microbenchmark::microbenchmark(TBM = tmb(), Implementation = imp(), 
                                 times = 10)
})
```

Finally, notice that we have called more than one C++ function from R from  
the `src/R-interface.cpp` file shown below

```{r show_r_interface, engine="C++", code = readLines("src/R-interface.cpp"), eval = FALSE}
```
